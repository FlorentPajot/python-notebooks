{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.10 |Anaconda 2.5.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \n",
      "[GCC 4.2.1 (Apple Inc. build 5577)]\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import (division, print_function)\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/florentpajot/Code/Python-SQLI/sqli/sqli/Data/\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAFsCAYAAABvrmq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlIg/dB3HcUrk/wIjSQW501rAVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b4b0a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_path = os.getcwd()\n",
    "data_folder = os.path.join(base_path, 'Data/')\n",
    "print(data_folder)\n",
    "\n",
    "# reading files\n",
    "train_file = os.path.join(data_folder, 'train.csv')\n",
    "train_set = np.recfromcsv(train_file, delimiter=',', skip_header=0, dtype=int, filling_values=np.nan, case_sensitive=True, deletechars='', replace_space=' ')\n",
    "\n",
    "test_file = os.path.join(data_folder, 'test.csv')\n",
    "test_set = np.recfromcsv(test_file, delimiter=',', skip_header=0, dtype=int, filling_values=np.nan, case_sensitive=True, deletechars='', replace_space=' ')\n",
    "\n",
    "#converting files to a list of np arrays\n",
    "train_set = train_set.tolist()\n",
    "test_set = test_set.tolist()\n",
    "\n",
    "train_set = [np.array(record, dtype=np.int32) for record in train_set]\n",
    "test_set = [np.array(record, dtype=np.int32) for record in test_set]\n",
    "\n",
    "#divide train set into data and labels\n",
    "m = len(train_set)\n",
    "train_set = np.array(train_set).reshape(m, -1)\n",
    "labels = [record[0] for record in train_set]\n",
    "train_set = [record[1:] for record in train_set]\n",
    "\n",
    "# Scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_set = scaler.fit_transform(train_set).astype(np.float32)\n",
    "test_set = scaler.transform(test_set).astype(np.float32)\n",
    "\n",
    "# visualizing one image per class\n",
    "figs, axes = plt.subplots(4,4, figsize=(6, 6))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[i, j].imshow(train_set[i + 4*j].reshape(28,28), cmap='gray', interpolation='none')\n",
    "        axes[i, j].set_xticks([])\n",
    "        axes[i, j].set_yticks([])\n",
    "        axes[i, j].set_title(\"Label: {}\".format(labels[i + 4 * j]))\n",
    "        axes[i, j].axis('off')\n",
    "#plt.axis('off')\n",
    "#plt.imshow(train_set[1].reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "# cross validation with 1 fold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "splits = StratifiedShuffleSplit(labels, n_iter=1, test_size=0.3, random_state=1)\n",
    "\n",
    "for t_i, v_i in splits:\n",
    "    # Compute the train set\n",
    "    train = np.array([train_set[i] for i in t_i])\n",
    "    t_labels = np.array([labels[i] for i in t_i])\n",
    "    # Compute the validation set\n",
    "    val = np.array([train_set[i] for i in v_i])\n",
    "    v_labels = np.array([labels[i] for i in v_i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type                      Data/Info\n",
      "------------------------------------------------------------\n",
      "Activation               type                      <class 'keras.layers.core.Activation'>\n",
      "Dense                    type                      <class 'keras.layers.core.Dense'>\n",
      "Dropout                  type                      <class 'keras.layers.core.Dropout'>\n",
      "Input                    function                  <function Input at 0x10c45bcf8>\n",
      "Model                    type                      <class 'keras.engine.training.Model'>\n",
      "SGD                      type                      <class 'keras.optimizers.SGD'>\n",
      "Sequential               type                      <class 'keras.models.Sequential'>\n",
      "StandardScaler           type                      <class 'sklearn.preproces<...>ing.data.StandardScaler'>\n",
      "StratifiedShuffleSplit   ABCMeta                   <class 'sklearn.cross_val<...>.StratifiedShuffleSplit'>\n",
      "axes                     ndarray                   4x4: 16 elems, type `object`, 128 bytes\n",
      "base_path                str                       /Users/florentpajot/Code/Python-SQLI/sqli/sqli\n",
      "data                     ndarray                   1000x784: 784000 elems, type `float64`, 6272000 bytes (5 Mb)\n",
      "data_folder              str                       /Users/florentpajot/Code/<...>thon-SQLI/sqli/sqli/Data/\n",
      "division                 __future__._Feature       _Feature((2, 2, 0, 'alpha<...> 0, 0, 'alpha', 0), 8192)\n",
      "f1_score                 function                  <function f1_score at 0x16d9be848>\n",
      "figs                     Figure                    Figure(480x480)\n",
      "i                        int                       0\n",
      "j                        int                       3\n",
      "keras                    module                    <module 'keras' from '/Us<...>ages/keras/__init__.pyc'>\n",
      "kerasNet1                Sequential                <keras.models.Sequential object at 0x125f2e4d0>\n",
      "labels                   list                      n=42000\n",
      "lasagne                  module                    <module 'lasagne' from '/<...>es/lasagne/__init__.pyc'>\n",
      "m                        int                       42000\n",
      "n                        module                    <module 'numpy' from '/Us<...>ages/numpy/__init__.pyc'>\n",
      "np                       module                    <module 'numpy' from '/Us<...>ages/numpy/__init__.pyc'>\n",
      "os                       module                    <module 'os' from '/Users<...>da/lib/python2.7/os.pyc'>\n",
      "pd                       module                    <module 'pandas' from '/U<...>ges/pandas/__init__.pyc'>\n",
      "plt                      module                    <module 'matplotlib.pyplo<...>s/matplotlib/pyplot.pyc'>\n",
      "prediction               ndarray                   12600x10: 126000 elems, type `float64`, 1008000 bytes (984 kb)\n",
      "print_function           __future__._Feature       _Feature((2, 6, 0, 'alpha<...>0, 0, 'alpha', 0), 65536)\n",
      "record                   ndarray                   785: 785 elems, type `int32`, 3140 bytes\n",
      "scaler                   StandardScaler            StandardScaler(copy=True,<...>mean=True, with_std=True)\n",
      "sgd                      SGD                       <keras.optimizers.SGD object at 0x125f2e3d0>\n",
      "splits                   StratifiedShuffleSplit    StratifiedShuffleSplit(la<...>size=0.3, random_state=1)\n",
      "sys                      module                    <module 'sys' (built-in)>\n",
      "t_binary_labels          ndarray                   29400x10: 294000 elems, type `float64`, 2352000 bytes (2 Mb)\n",
      "t_i                      ndarray                   29400: 29400 elems, type `int64`, 235200 bytes (229 kb)\n",
      "t_labels                 ndarray                   29400: 29400 elems, type `int32`, 117600 bytes (114 kb)\n",
      "test_file                str                       /Users/florentpajot/Code/<...>I/sqli/sqli/Data/test.csv\n",
      "test_set                 ndarray                   28000x784: 21952000 elems, type `float32`, 87808000 bytes (83 Mb)\n",
      "to_categorical           function                  <function to_categorical at 0x10d1b65f0>\n",
      "train                    ndarray                   29400x784: 23049600 elems, type `float32`, 92198400 bytes (87 Mb)\n",
      "train_file               str                       /Users/florentpajot/Code/<...>/sqli/sqli/Data/train.csv\n",
      "train_set                ndarray                   42000x784: 32928000 elems, type `float32`, 131712000 bytes (125 Mb)\n",
      "v_binary_labels          ndarray                   12600x10: 126000 elems, type `float64`, 1008000 bytes (984 kb)\n",
      "v_i                      ndarray                   12600: 12600 elems, type `int64`, 100800 bytes (98 kb)\n",
      "v_labels                 ndarray                   12600: 12600 elems, type `int32`, 50400 bytes\n",
      "val                      ndarray                   12600x784: 9878400 elems, type `float32`, 39513600 bytes (37 Mb)\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.reshape(-1, 1, 28, 28)\n",
    "val = val.reshape(-1, 1, 28, 28)\n",
    "\n",
    "net1 = NeuralNet(\n",
    "        layers=[('input', layers.InputLayer),\n",
    "                ('hidden', layers.DenseLayer),\n",
    "                ('output', layers.DenseLayer)],\n",
    "        #layer parameters:\n",
    "        input_shape=(None,1,28,28),\n",
    "        hidden_num_units=200,\n",
    "        output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        output_num_units=10,\n",
    "        \n",
    "        #opitmization method:\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=0.001,\n",
    "        update_momentum=0.9,\n",
    "        max_epochs=5,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 159010 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name    size\n",
      "---  ------  -------\n",
      "  0  input   1x28x28\n",
      "  1  hidden  200\n",
      "  2  output  10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net1.fit(train, t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CNN(n_epochs):\n",
    "    net1 = NeuralNet(\n",
    "        layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),      #Convolutional layer.  Params defined below\n",
    "        ('pool1', layers.MaxPool2DLayer),   # Like downsampling, for execution speed\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('hidden3', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "\n",
    "    input_shape=(None, 1, 28, 28),\n",
    "    conv1_num_filters=7, \n",
    "    conv1_filter_size=(3, 3), \n",
    "    conv1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        \n",
    "    pool1_pool_size=(2, 2),\n",
    "        \n",
    "    conv2_num_filters=12, \n",
    "    conv2_filter_size=(2, 2),    \n",
    "    conv2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        \n",
    "    hidden3_num_units=1000,\n",
    "    output_num_units=10, \n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "\n",
    "    update_learning_rate=0.0001,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    max_epochs=n_epochs,\n",
    "    verbose=1,\n",
    "    )\n",
    "    return net1\n",
    "\n",
    "cnn = CNN(15).fit(train,target) # train the CNN model for 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29400 samples, validate on 12600 samples\n",
      "Epoch 1/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.9119 - acc: 0.7437 - val_loss: 0.4755 - val_acc: 0.8726\n",
      "Epoch 2/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.3981 - acc: 0.8932 - val_loss: 0.3663 - val_acc: 0.8977\n",
      "Epoch 3/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.3196 - acc: 0.9108 - val_loss: 0.3199 - val_acc: 0.9103\n",
      "Epoch 4/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.2781 - acc: 0.9213 - val_loss: 0.2921 - val_acc: 0.9194\n",
      "Epoch 5/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.2501 - acc: 0.9295 - val_loss: 0.2724 - val_acc: 0.9232\n",
      "Epoch 6/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.2294 - acc: 0.9353 - val_loss: 0.2576 - val_acc: 0.9270\n",
      "Epoch 7/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.2132 - acc: 0.9397 - val_loss: 0.2457 - val_acc: 0.9321\n",
      "Epoch 8/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1995 - acc: 0.9440 - val_loss: 0.2363 - val_acc: 0.9352\n",
      "Epoch 9/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1880 - acc: 0.9474 - val_loss: 0.2286 - val_acc: 0.9369\n",
      "Epoch 10/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1780 - acc: 0.9506 - val_loss: 0.2215 - val_acc: 0.9387\n",
      "Epoch 11/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1691 - acc: 0.9532 - val_loss: 0.2156 - val_acc: 0.9397\n",
      "Epoch 12/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1614 - acc: 0.9554 - val_loss: 0.2103 - val_acc: 0.9410\n",
      "Epoch 13/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1542 - acc: 0.9573 - val_loss: 0.2056 - val_acc: 0.9432\n",
      "Epoch 14/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1479 - acc: 0.9598 - val_loss: 0.2013 - val_acc: 0.9441\n",
      "Epoch 15/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1420 - acc: 0.9614 - val_loss: 0.1976 - val_acc: 0.9447\n",
      "Epoch 16/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1365 - acc: 0.9630 - val_loss: 0.1939 - val_acc: 0.9463\n",
      "Epoch 17/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1317 - acc: 0.9645 - val_loss: 0.1908 - val_acc: 0.9474\n",
      "Epoch 18/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1270 - acc: 0.9659 - val_loss: 0.1878 - val_acc: 0.9477\n",
      "Epoch 19/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1227 - acc: 0.9674 - val_loss: 0.1853 - val_acc: 0.9477\n",
      "Epoch 20/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1187 - acc: 0.9690 - val_loss: 0.1829 - val_acc: 0.9483\n",
      "Epoch 21/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1148 - acc: 0.9697 - val_loss: 0.1807 - val_acc: 0.9487\n",
      "Epoch 22/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1113 - acc: 0.9706 - val_loss: 0.1782 - val_acc: 0.9490\n",
      "Epoch 23/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.1080 - acc: 0.9719 - val_loss: 0.1764 - val_acc: 0.9498\n",
      "Epoch 24/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1049 - acc: 0.9726 - val_loss: 0.1746 - val_acc: 0.9503\n",
      "Epoch 25/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.1019 - acc: 0.9736 - val_loss: 0.1729 - val_acc: 0.9508\n",
      "Epoch 26/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0990 - acc: 0.9750 - val_loss: 0.1716 - val_acc: 0.9514\n",
      "Epoch 27/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0963 - acc: 0.9758 - val_loss: 0.1700 - val_acc: 0.9523\n",
      "Epoch 28/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0937 - acc: 0.9770 - val_loss: 0.1684 - val_acc: 0.9522\n",
      "Epoch 29/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0913 - acc: 0.9774 - val_loss: 0.1672 - val_acc: 0.9527\n",
      "Epoch 30/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0889 - acc: 0.9780 - val_loss: 0.1658 - val_acc: 0.9525\n",
      "Epoch 31/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0868 - acc: 0.9787 - val_loss: 0.1645 - val_acc: 0.9533\n",
      "Epoch 32/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0845 - acc: 0.9793 - val_loss: 0.1636 - val_acc: 0.9537\n",
      "Epoch 33/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0825 - acc: 0.9796 - val_loss: 0.1626 - val_acc: 0.9544\n",
      "Epoch 34/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0805 - acc: 0.9804 - val_loss: 0.1616 - val_acc: 0.9540\n",
      "Epoch 35/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0787 - acc: 0.9808 - val_loss: 0.1607 - val_acc: 0.9543\n",
      "Epoch 36/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0768 - acc: 0.9814 - val_loss: 0.1600 - val_acc: 0.9543\n",
      "Epoch 37/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0751 - acc: 0.9820 - val_loss: 0.1588 - val_acc: 0.9547\n",
      "Epoch 38/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0733 - acc: 0.9827 - val_loss: 0.1581 - val_acc: 0.9549\n",
      "Epoch 39/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0717 - acc: 0.9832 - val_loss: 0.1574 - val_acc: 0.9551\n",
      "Epoch 40/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0701 - acc: 0.9833 - val_loss: 0.1564 - val_acc: 0.9556\n",
      "Epoch 41/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0686 - acc: 0.9842 - val_loss: 0.1557 - val_acc: 0.9556\n",
      "Epoch 42/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0671 - acc: 0.9846 - val_loss: 0.1553 - val_acc: 0.9560\n",
      "Epoch 43/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0657 - acc: 0.9850 - val_loss: 0.1544 - val_acc: 0.9567\n",
      "Epoch 44/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0643 - acc: 0.9854 - val_loss: 0.1538 - val_acc: 0.9565\n",
      "Epoch 45/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0629 - acc: 0.9856 - val_loss: 0.1534 - val_acc: 0.9565\n",
      "Epoch 46/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0617 - acc: 0.9860 - val_loss: 0.1527 - val_acc: 0.9565\n",
      "Epoch 47/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0604 - acc: 0.9865 - val_loss: 0.1521 - val_acc: 0.9571\n",
      "Epoch 48/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0592 - acc: 0.9869 - val_loss: 0.1515 - val_acc: 0.9573\n",
      "Epoch 49/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0580 - acc: 0.9871 - val_loss: 0.1511 - val_acc: 0.9575\n",
      "Epoch 50/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0569 - acc: 0.9875 - val_loss: 0.1507 - val_acc: 0.9575\n",
      "Epoch 51/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0558 - acc: 0.9880 - val_loss: 0.1503 - val_acc: 0.9577\n",
      "Epoch 52/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0546 - acc: 0.9885 - val_loss: 0.1497 - val_acc: 0.9581\n",
      "Epoch 53/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0536 - acc: 0.9884 - val_loss: 0.1495 - val_acc: 0.9585\n",
      "Epoch 54/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0526 - acc: 0.9891 - val_loss: 0.1491 - val_acc: 0.9585\n",
      "Epoch 55/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0516 - acc: 0.9893 - val_loss: 0.1487 - val_acc: 0.9587\n",
      "Epoch 56/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0506 - acc: 0.9896 - val_loss: 0.1483 - val_acc: 0.9590\n",
      "Epoch 57/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0498 - acc: 0.9901 - val_loss: 0.1479 - val_acc: 0.9592\n",
      "Epoch 58/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0488 - acc: 0.9901 - val_loss: 0.1477 - val_acc: 0.9593\n",
      "Epoch 59/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0479 - acc: 0.9902 - val_loss: 0.1474 - val_acc: 0.9598\n",
      "Epoch 60/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0471 - acc: 0.9905 - val_loss: 0.1470 - val_acc: 0.9601\n",
      "Epoch 61/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0463 - acc: 0.9909 - val_loss: 0.1465 - val_acc: 0.9603\n",
      "Epoch 62/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0455 - acc: 0.9911 - val_loss: 0.1464 - val_acc: 0.9602\n",
      "Epoch 63/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0447 - acc: 0.9910 - val_loss: 0.1462 - val_acc: 0.9602\n",
      "Epoch 64/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0439 - acc: 0.9914 - val_loss: 0.1461 - val_acc: 0.9600\n",
      "Epoch 65/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0432 - acc: 0.9916 - val_loss: 0.1457 - val_acc: 0.9605\n",
      "Epoch 66/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0424 - acc: 0.9919 - val_loss: 0.1455 - val_acc: 0.9606\n",
      "Epoch 67/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0417 - acc: 0.9922 - val_loss: 0.1451 - val_acc: 0.9603\n",
      "Epoch 68/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0410 - acc: 0.9921 - val_loss: 0.1449 - val_acc: 0.9603\n",
      "Epoch 69/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0403 - acc: 0.9923 - val_loss: 0.1448 - val_acc: 0.9604\n",
      "Epoch 70/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0397 - acc: 0.9927 - val_loss: 0.1445 - val_acc: 0.9605\n",
      "Epoch 71/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0391 - acc: 0.9929 - val_loss: 0.1443 - val_acc: 0.9612\n",
      "Epoch 72/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0384 - acc: 0.9931 - val_loss: 0.1441 - val_acc: 0.9610\n",
      "Epoch 73/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0378 - acc: 0.9934 - val_loss: 0.1439 - val_acc: 0.9615\n",
      "Epoch 74/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0372 - acc: 0.9935 - val_loss: 0.1437 - val_acc: 0.9613\n",
      "Epoch 75/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0367 - acc: 0.9938 - val_loss: 0.1436 - val_acc: 0.9611\n",
      "Epoch 76/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0361 - acc: 0.9939 - val_loss: 0.1435 - val_acc: 0.9611\n",
      "Epoch 77/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0356 - acc: 0.9941 - val_loss: 0.1433 - val_acc: 0.9613\n",
      "Epoch 78/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0350 - acc: 0.9942 - val_loss: 0.1433 - val_acc: 0.9614\n",
      "Epoch 79/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0345 - acc: 0.9943 - val_loss: 0.1431 - val_acc: 0.9615\n",
      "Epoch 80/100\n",
      "29400/29400 [==============================] - 2s - loss: 0.0340 - acc: 0.9946 - val_loss: 0.1431 - val_acc: 0.9612\n",
      "Epoch 81/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0335 - acc: 0.9947 - val_loss: 0.1429 - val_acc: 0.9612\n",
      "Epoch 82/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0331 - acc: 0.9949 - val_loss: 0.1426 - val_acc: 0.9619\n",
      "Epoch 83/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0326 - acc: 0.9950 - val_loss: 0.1428 - val_acc: 0.9613\n",
      "Epoch 84/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0321 - acc: 0.9951 - val_loss: 0.1426 - val_acc: 0.9616\n",
      "Epoch 85/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0316 - acc: 0.9953 - val_loss: 0.1426 - val_acc: 0.9617\n",
      "Epoch 86/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0312 - acc: 0.9956 - val_loss: 0.1424 - val_acc: 0.9617\n",
      "Epoch 87/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0308 - acc: 0.9956 - val_loss: 0.1423 - val_acc: 0.9615\n",
      "Epoch 88/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0304 - acc: 0.9958 - val_loss: 0.1422 - val_acc: 0.9618\n",
      "Epoch 89/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0299 - acc: 0.9959 - val_loss: 0.1420 - val_acc: 0.9617\n",
      "Epoch 90/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0295 - acc: 0.9959 - val_loss: 0.1419 - val_acc: 0.9617\n",
      "Epoch 91/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0291 - acc: 0.9961 - val_loss: 0.1419 - val_acc: 0.9619\n",
      "Epoch 92/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0288 - acc: 0.9961 - val_loss: 0.1418 - val_acc: 0.9621\n",
      "Epoch 93/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0284 - acc: 0.9963 - val_loss: 0.1418 - val_acc: 0.9619\n",
      "Epoch 94/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0280 - acc: 0.9964 - val_loss: 0.1419 - val_acc: 0.9618\n",
      "Epoch 95/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0277 - acc: 0.9966 - val_loss: 0.1416 - val_acc: 0.9618\n",
      "Epoch 96/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0273 - acc: 0.9969 - val_loss: 0.1416 - val_acc: 0.9616\n",
      "Epoch 97/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0270 - acc: 0.9967 - val_loss: 0.1416 - val_acc: 0.9619\n",
      "Epoch 98/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0266 - acc: 0.9968 - val_loss: 0.1414 - val_acc: 0.9619\n",
      "Epoch 99/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0263 - acc: 0.9970 - val_loss: 0.1416 - val_acc: 0.9619\n",
      "Epoch 100/100\n",
      "29400/29400 [==============================] - 1s - loss: 0.0260 - acc: 0.9969 - val_loss: 0.1414 - val_acc: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128f80710>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sale thing using Keras (keras.io)\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Keras is based on a Sequential model (we pass a list of layers to the constructor)\n",
    "kerasNet1 = Sequential([\n",
    "        Dense(200, batch_input_shape=(None,784)), #None means batch of any size\n",
    "        Activation('relu'), # C'est quoi ?\n",
    "        Dense(10),\n",
    "        Activation('softmax'),\n",
    "    ])\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Configuring the learning process\n",
    "kerasNet1.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "train = train.reshape(-1, 784)\n",
    "\n",
    "# Keras needs us to convert our labels to binary formats (but provides a super tool for it :))\n",
    "from keras.utils.np_utils import to_categorical\n",
    "t_binary_labels = to_categorical(t_labels)\n",
    "v_binary_labels = to_categorical(v_labels)\n",
    "\n",
    "# training the NN\n",
    "kerasNet1.fit(train, t_binary_labels, nb_epoch=100, batch_size=100, validation_data=(val, v_binary_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of binary and continuous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7454e132188a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mv_binary_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_binary_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/florentpajot/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    637\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    638\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/florentpajot/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    754\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/florentpajot/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/florentpajot/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of binary and continuous"
     ]
    }
   ],
   "source": [
    "# Prediction sur validation\n",
    "val = val.reshape(-1, 784)\n",
    "prediction = kerasNet1.predict(val, r)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "v_binary_labels = to_categorical(v_labels)\n",
    "for i in range(10):\n",
    "    f1_score(v_binary_labels[:,i], prediction[:,i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-141e897a5894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkerasNet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "kerasNet1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
