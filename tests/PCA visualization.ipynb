{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA & IPCA test\n",
    "### @author: Florent Pajot\n",
    "### @version: 1.0\n",
    "### @date: 09/11/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "def getFullSet():\n",
    "    # Load data from the titanic Kaggle competition\n",
    "    file_path_train = \"C:\\\\Users\\\\fpajot\\\\Documents\\\\Code\\\\public-github\\\\data\\\\titanic_train.csv\"\n",
    "    file_path_test = \"C:\\\\Users\\\\fpajot\\\\Documents\\\\Code\\\\public-github\\\\data\\\\titanic_train.csv\"\n",
    "    train_set = pd.read_csv(file_path_train, sep=\",\")\n",
    "    test_set = pd.read_csv(file_path_train, sep=\",\")\n",
    "    y_train = train_set.Survived\n",
    "    train_set = train_set.assign(cat = lambda x:1)\n",
    "    test_set = test_set.assign(cat = lambda x:0)\n",
    "    full_set = pd.concat([train_set, test_set], axis=0)\n",
    "    # Fill NAs or drop columns for the purpose of this test\n",
    "    full_set.Embarked.fillna(value=\"S\", inplace=True)\n",
    "    age_mean_per_sex = full_set.groupby('Sex').Age.apply(np.mean)\n",
    "    full_set.loc[full_set.Age.isnull() & (full_set.Sex == 'female'),'Age'] = age_mean_per_sex[0]\n",
    "    full_set.loc[full_set.Age.isnull() & (full_set.Sex == 'male'),'Age'] = age_mean_per_sex[1]\n",
    "    full_set.drop(['Cabin', 'Name', 'Ticket','PassengerId','Survived'], axis=1, inplace=True)\n",
    "    # Encode labels\n",
    "    encoder = LabelEncoder()\n",
    "    full_set.Sex = encoder.fit_transform(full_set.Sex)\n",
    "    full_set.Embarked = encoder.fit_transform(full_set.Embarked)\n",
    "    return full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WARNING: we shoud take care of normalizing and transforming skewed features before applying PCA\n",
    "# however, for the purpose of this example we won't do it\n",
    "# Normalizaing data\n",
    "#from sklearn.preprocessing import normalize\n",
    "full_set = getFullSet()\n",
    "#full_set_norm = pd.DataFrame(normalize(full_set, axis=0), columns=full_set.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INFO: IPCA is an optimized version of PCA useful for large datasets (more memory efficient)\n",
    "\n",
    "'''\n",
    "@author: Florent Pajot\n",
    "@version: 1.0\n",
    "@params:\n",
    "    - dataset (DataFrame): the input DataFrame to reduce using IPCA method\n",
    "    - variance_threshold (float): the cumulated ratio of explained variance to keep when selecting principal components\n",
    "    - verbose (int): 1 (default) for displaying principal components selection details, 0 otherwise (nothing displayed)\n",
    "@result: returns a DataFrame of the resulting projection of the dataset in the new space\n",
    "'''\n",
    "\n",
    "# WARNING: it has to be carefully used to avoid information loss or distortion\n",
    "# i.e. take care of normalizing features before applying PCA\n",
    "\n",
    "def applyIPCA(dataset, variance_threshold, verbose=1):\n",
    "    \n",
    "    # parameters n_components set to default value min(n_features, n_samples)\n",
    "    # and batch_size set to default value to 5 * n_features\n",
    "    ipca = IncrementalPCA()\n",
    "    X_ipca = ipca.fit_transform(dataset)\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print \"--> Initial dimensions:\", dataset.shape\n",
    "        print \"--> With columns:\", dataset.columns.values\n",
    "        print \"\\n-------------------------------------\\n\"\n",
    "        print \"--> Features projection in the new space:\\n\"\n",
    "        print pd.DataFrame(ipca.components_, columns=[\"PC\"+str(i) for i in range(ipca.components_.shape[1])], index=dataset.columns)\n",
    "        print \"\\n--> Variance explained by each new component space:\\n\"\n",
    "    \n",
    "    cumulated_variance = [sum(ipca.explained_variance_ratio_[:i]) for i in range(ipca.components_.shape[1]+1)][1:ipca.components_.shape[1]+1]\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print pd.DataFrame([ipca.explained_variance_,ipca.explained_variance_ratio_,cumulated_variance], columns=[\"PC\"+str(i) for i in range(ipca.components_.shape[1])], index=[\"explained_variace\", \"explained_variance_ratio\", \"cumulated_variance_explained\"])\n",
    "\n",
    "    # Feature selection using variance cutoff\n",
    "    index_cutoff = ipca.components_.shape[1]\n",
    "    stop = False\n",
    "    while stop == False:\n",
    "        if cumulated_variance[index_cutoff - 2] < variance_threshold:\n",
    "            stop = True\n",
    "        else:\n",
    "            index_cutoff = index_cutoff - 1\n",
    "    \n",
    "    if verbose == 1:            \n",
    "        print \"\\nNumber of components needed to reach the variance threshold:\", index_cutoff\n",
    "    \n",
    "    ### \n",
    "    X_ipca_reduced = X_ipca[:,range(index_cutoff)]\n",
    "    if verbose == 1:\n",
    "        print \"\\n--> Final dimensions:\", X_ipca_reduced.shape\n",
    "    return pd.DataFrame(X_ipca_reduced, columns=dataset.columns.values[0:index_cutoff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Initial dimensions: (1782, 8)\n",
      "--> With columns: ['Pclass' 'Sex' 'Age' 'SibSp' 'Parch' 'Fare' 'Embarked' 'cat']\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "--> Features projection in the new space:\n",
      "\n",
      "               PC0       PC1       PC2       PC3       PC4       PC5  \\\n",
      "Pclass   -0.009274 -0.001746  0.025031  0.003506  0.003487  0.999624   \n",
      "Sex      -0.018047  0.004476  0.999196 -0.021709 -0.012779 -0.025059   \n",
      "Age       0.125933 -0.044705  0.026961  0.888685  0.409523 -0.003577   \n",
      "SibSp     0.069184  0.086390 -0.002613 -0.178919  0.007350  0.004961   \n",
      "Parch     0.069028 -0.196558  0.004358 -0.414559  0.883073 -0.001689   \n",
      "Fare      0.976795  0.153271  0.014445 -0.075180 -0.085180  0.009186   \n",
      "Embarked  0.000360 -0.000292 -0.000007  0.000253 -0.000440  0.000006   \n",
      "cat      -0.141593  0.963529 -0.004520 -0.015228  0.212102 -0.000489   \n",
      "\n",
      "               PC6       PC7  \n",
      "Pclass   -0.003580 -0.000002  \n",
      "Sex      -0.000198  0.000015  \n",
      "Age       0.154699 -0.000123  \n",
      "SibSp     0.977575 -0.000081  \n",
      "Parch    -0.070008  0.000420  \n",
      "Fare     -0.095801 -0.000313  \n",
      "Embarked  0.000132  1.000000  \n",
      "cat      -0.079520  0.000440  \n",
      "\n",
      "--> Variance explained by each new component space:\n",
      "\n",
      "                                      PC0         PC1       PC2       PC3  \\\n",
      "explained_variace             2467.582913  167.857692  1.270105  0.581819   \n",
      "explained_variance_ratio         0.934857    0.063594  0.000481  0.000220   \n",
      "cumulated_variance_explained     0.934857    0.998451  0.998932  0.999153   \n",
      "\n",
      "                                   PC4       PC5       PC6       PC7  \n",
      "explained_variace             0.469989  0.421341  0.246486  0.196392  \n",
      "explained_variance_ratio      0.000178  0.000160  0.000093  0.000074  \n",
      "cumulated_variance_explained  0.999331  0.999491  0.999584  0.999658  \n",
      "\n",
      "Number of components needed to reach the variance threshold: 4\n",
      "\n",
      "--> Final dimensions: (1782L, 4L)\n"
     ]
    }
   ],
   "source": [
    "full_set_with_pca = applyIPCA(dataset=full_set, variance_threshold=0.999, verbose=1)\n",
    "#full_set_with_pca = applyIPCA(dataset=full_set_norm, variance_threshold=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.782000e+03</td>\n",
       "      <td>1.782000e+03</td>\n",
       "      <td>1.782000e+03</td>\n",
       "      <td>1.782000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.046675e-14</td>\n",
       "      <td>-1.789565e-15</td>\n",
       "      <td>-1.317689e-16</td>\n",
       "      <td>-3.918801e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.969712e+01</td>\n",
       "      <td>1.296205e+01</td>\n",
       "      <td>1.127459e+00</td>\n",
       "      <td>7.632012e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.247266e+01</td>\n",
       "      <td>-3.178953e+01</td>\n",
       "      <td>-2.614651e+00</td>\n",
       "      <td>-1.769483e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.428631e+01</td>\n",
       "      <td>-7.120523e+00</td>\n",
       "      <td>-6.082505e-01</td>\n",
       "      <td>-4.821712e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.781299e+01</td>\n",
       "      <td>-1.400369e-01</td>\n",
       "      <td>-3.620849e-01</td>\n",
       "      <td>3.906089e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.396369e+00</td>\n",
       "      <td>5.212809e+00</td>\n",
       "      <td>2.859130e-01</td>\n",
       "      <td>4.976388e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.801184e+02</td>\n",
       "      <td>5.032011e+01</td>\n",
       "      <td>7.343684e+00</td>\n",
       "      <td>1.421686e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass           Sex           Age         SibSp\n",
       "count  1.782000e+03  1.782000e+03  1.782000e+03  1.782000e+03\n",
       "mean  -1.046675e-14 -1.789565e-15 -1.317689e-16 -3.918801e-17\n",
       "std    4.969712e+01  1.296205e+01  1.127459e+00  7.632012e-01\n",
       "min   -3.247266e+01 -3.178953e+01 -2.614651e+00 -1.769483e+00\n",
       "25%   -2.428631e+01 -7.120523e+00 -6.082505e-01 -4.821712e-01\n",
       "50%   -1.781299e+01 -1.400369e-01 -3.620849e-01  3.906089e-01\n",
       "75%   -1.396369e+00  5.212809e+00  2.859130e-01  4.976388e-01\n",
       "max    4.801184e+02  5.032011e+01  7.343684e+00  1.421686e+00"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_set_with_pca.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
