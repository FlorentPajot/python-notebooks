{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Kaggle Competition - Image Processing</h1>\n",
    "<img src=https://www.kaggle.com/content/v/4e5085eca1ab/kaggle/img/logos/kaggle-logo-transparent-300.png>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Author : Florent Pajot\n",
    "Data : 17 mai 2016\n",
    "version : 1.0\n",
    "Langage : Python 2.7\n",
    "Contenu : \n",
    "    - Participation à une compétition de Data Science sur Kaggle\n",
    "    - Découvrir les bases du traitement d'image en Python\n",
    "Prérequis : numpy, csv, sklearn, Theano, Keras"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SOMMAIRE :\n",
    "    Partie I\n",
    "        a - Quelques bases Python\n",
    "        b - Introduction à la compétition Kaggle Digit Recognizer\n",
    "    Partie II\n",
    "        a - Méthodologie pour participer à une compétition Kaggle\n",
    "        b - Passage à la pratique : classification d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Part 1: **\n",
    "## **A - Quelques bases en Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Usage du notebook en Python **\n",
    "#### ** Quelques raccourcis sympas : **\n",
    "#### ** Ctrl + Entrer = executer la cellule **\n",
    "#### ** Maj + Entrer = executer la cellule et sélectionner la suivante **\n",
    "#### ** Sélectionner une cellule + B = créer une céllule à la suite **\n",
    "#### ** Sélectionner une cellule + D (2 fois) = supprimer la cellule sélectionnée (ATTENTION PAS RETOUR POSSIBLE) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** String, variable, import **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a Python cell. You can run normal Python code here...\n",
    "print 'The sum of 1 and 1 is {0}'.format(1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is another Python cell, this time with a variable (x) declaration and an if statement:\n",
    "x = 42\n",
    "if x > 40:\n",
    "    print 'The sum of 1 and 2 is {0}'.format(1+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell relies on x being defined already.\n",
    "# If we didn't run the cells from part (1a) this code would fail.\n",
    "print x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the regular expression library\n",
    "import re\n",
    "m = re.search('(?<=abc)def', 'abcdef')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the datetime library\n",
    "import datetime\n",
    "print 'This was last run on: {0}'.format(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Python List, Dict and Set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = ['a', 'b', 'c', 'b']\n",
    "print l\n",
    "\n",
    "dic = {'a' : 1, 'b': \"2\", 'c' : 44}\n",
    "print dic\n",
    "\n",
    "s = set(l)\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO, vérifier que la lettre \"c\" est dans le set \"s\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Numpy **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Numpy est un outil très populaire en Python car il permet de manipuler plus efficacement des tableaux et matrices qu'avec le type \"liste\" standard de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Création d'une liste d'entiers de 0 à 9\n",
    "range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# avec Numpy\n",
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npa = np.arange(10)\n",
    "?npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# affichage des dimensions\n",
    "print np.shape(npa)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Il est notamment plus simple d'accéder à des méthodes de base comme des fonction de description statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npa.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npa.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npa.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Et on peut manipuler les matrices numpy comme des listes classiques en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[x * x for x in npa]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D'autres outils bien pratiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boolean test\n",
    "npa % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boolean filter\n",
    "npa[npa % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with a substancial gain in performance\n",
    "np2 = np.arange(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [x for x in np2 if x % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit np2[np2 % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Part 2: **\n",
    "## **B - Passage à la pratique : classification d'images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "print sys.version\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 1 - Importer, explorer et préparer la donnée**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO, définissez le chemin d'accès à vos fichiers\n",
    "base_path = os.getcwd()\n",
    "digit_recognizer_path = os.path.join(base_path, 'A REMPLIR')\n",
    "print digit_recognizer_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import des données\n",
    "import csv\n",
    "# train set\n",
    "train_file = os.path.join(digit_recognizer_path, 'train.csv')\n",
    "train_set = np.recfromcsv(train_file, delimiter=',', skip_header=0, dtype=int, filling_values=np.nan, case_sensitive=True, deletechars='', replace_space=' ')\n",
    "# test set\n",
    "test_file = os.path.join(digit_recognizer_path, 'test.csv')\n",
    "test_set = np.recfromcsv(test_file, delimiter=',', skip_header=0, dtype=int, filling_values=np.nan, case_sensitive=True, deletechars='', replace_space=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO afficher le premier élément du jeu de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO afficher la taille du train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transfirmation des jeux de données en matrices\n",
    "train_set = [np.array(record.tolist()) for record in train_set]\n",
    "test_set = [np.array(record.tolist()) for record in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO, extraire les labels du train set\n",
    "labels = \n",
    "train_set = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On visualize notre train_set\n",
    "plt.axis('off')\n",
    "plt.imshow(train_set[10].reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On peut aussi afficher plusieurs images\n",
    "f, axes = plt.subplots(4,4, figsize=(10,10))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[i, j].imshow(train_set[4*i+j].reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        axes[i, j].axis('off')\n",
    "        axes[i, j].set_title(\"{}\".format(labels[4*i+j]))\n",
    "        axes[i, j].xticks = ()\n",
    "        axes[i, j].yticks = ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 2 - Pré-traitement de la donnée**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En fonction des algorithmes que l'on prévoit d'utiliser, mais aussi de la donnée que l'on manipule,\n",
    "il est bon d'effectuer un pré-traitement des données.\n",
    "Ce pré-traitement peut répondre à plusieurs objectifs parmi lesquels :\n",
    "- prévenir un disfonctionnement de notre modèle de machine learning (ex: k-means)\n",
    "- optimiser l'apprentissage d'un modèle (ex: learning rate ou réseaux de neurones)\n",
    "- enrichir le set de données dans le cas où notre modèle a un biais important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ici, nous allons centrer et réduire les données afin d'éviter les problèmes par la suite\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# TODO, centrer et réduire train_set et test_set\n",
    "\n",
    "scaled_test_set = \n",
    "scaled_train_set = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 3 - Construction d'un set de validation croisée**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dans une compétition Kaggle, on cherche à se positionner sur le Public Leaderboard, autrement dit sur le classement publique de la compétition qui est rafraichit en quasi temps réel.\n",
    "\n",
    "Le score affiché sur le Public Leaderboard représente la performance de notre modèle quand il est testé sur le \"test set\". Plus précisément, cette performance est évaluée sur un pourcentage restreint des données contenues dans le test set.\n",
    "\n",
    "Par exemple, si votre test set fait 10 000 lignes, votre score du Public Leaderboard sera évalué sur seulement 3 000 lignes du test set (toujours les mêmes quelque soit la soumission).\n",
    "\n",
    "C'est seulement à la fin de la compétition, lors des validations finales, que votre modèle sera évalué sur l'intégralité du test set. D'où l'importance de créer un modèle capable de bien se généraliser lorsqu'il est confronté à de nouvelles données.\n",
    "\n",
    "C'est dans cet objectif que l'on construit un set de validation croisée. Celui-ci va nous permettre de vérifier que notre modèle se généralise bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ici, nous allons utiliser la méthode la plus simple, celle du \"validation set\"\n",
    "import math, random\n",
    "\n",
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "def train_val_split(x, y, val_pct):\n",
    "    \"\"\"split data and corresponding labels into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = zip(x, y)                              \n",
    "    train, val = split_data(data, 1 - val_pct)  \n",
    "    x_train, y_train = zip(*train)                # magical un-zip trick\n",
    "    x_val, y_val = zip(*val)\n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "# On utilise les fonctions précédentes pour séparer le train set en 2 sets\n",
    "x_train, x_val, y_train, y_val = train_val_split(scaled_train_set, labels, val_pct = 0.33) #on prend 1/3\n",
    "print np.shape(x_train)\n",
    "print np.shape(y_train)\n",
    "print np.shape(x_val)\n",
    "print np.shape(y_val)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A noter que sklearn propose des librairies spécifiques pour créer un set de cross validation avec plusieurs techniques : sklearn.cross_validation.StratifiedShuffleSplit ou sklearn.cross_validation.cross_validation.KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 4 - Construction d'un modèle de référence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nous allons construire un modèle de type Random Forest qui nous servira de référence\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_tree = 50\n",
    "model_rf_1 = RandomForestClassifier(n_estimators=n_tree, n_jobs=-1)\n",
    "\n",
    "#TODO, utiliser le modèle pour déterminer le labels du test set\n",
    "\n",
    "results_rf_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO, afficher les 10 premiers résultats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 5 - Faire sa première soumission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pour gagner du temps par la suite, il est utile de construire une fonction qui permettra\n",
    "# d'écrire les résultats obtenus dans un fichier de soumission dans le format imposé\n",
    "def create_submission(submission_name, predictions):\n",
    "    file_name = submission_name + \".csv\"\n",
    "    with open(file_name, 'wb') as csvfile:\n",
    "        try:\n",
    "            writer = csv.writer(csvfile, delimiter=',', quotechar='|')\n",
    "            writer.writerow((\"ImageId\", \"Label\"))\n",
    "            for index, value in enumerate(predictions):\n",
    "                writer.writerow((index+1, value))\n",
    "        except:\n",
    "            print \"1 erreure rencontrer lors de l'écriture. Le fichier de soumission est invalide\"\n",
    "            pass\n",
    "    csvfile.close()\n",
    "# ATTENTION, le format de sortie est spécifique à la compétition Digit Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO, créez votre première soumission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 6 - Evaluer son modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nous allons utiliser le set de validation croisée de tout à l'heure\n",
    "# TODO, utiliser le modèle pour déterminer les labels du set de validation x_val\n",
    "predictions_rf_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Première évaluation de notre classifieur\n",
    "from sklearn import metrics\n",
    "# Tout d'abord le rapport de classification proposé dans sklearn\n",
    "print(\"Rapport de classification pour le modèle %s:\\n%s\\n\" % (model_rf_1, metrics.classification_report(y_val, predictions_rf_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensuite la matrice de confusion\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_val, predictions_rf_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Il est également utile de construire une méthode d'évaluation spécifique au concours\n",
    "from __future__ import division\n",
    "def evaluate_model(labels, predictions):\n",
    "    true_count = 0\n",
    "    for index, label in enumerate(labels):\n",
    "        if predictions[index] == label:\n",
    "            true_count +=1\n",
    "    return true_count/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 7 - Incrémentez ! Optimisation et test d'autres modèles**\n",
    "#### **Optimisation du RandomForest**\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Afin d'obtenir un meilleur score, on peut optimiser les hyper-paramètres du modèle. C'est parfois une tâche compliquée et chronophage qu'il est judicieux d'effectuer une fois que l'on est confiant dans l'efficacité potentielle du modèle, et que les variables qui alimentent celui-ci ont été travaillées (feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Peut-on faire mieux que précédemment en optimisant notre modèle ?\n",
    "# Par exemple, modifier le nombre d'arbres peut-il nous faire progresser ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test d'un nouveau modèle : le SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maintenant, testons un autre modèle de classification\n",
    "# Par exemple un SVM\n",
    "from sklearn import svm\n",
    "model_svm_1 = svm.SVC(C=1, gamma=0.001, cache_size=500)\n",
    "#TODO, évaluer le modèle sur le set de validation croisée\n",
    "\n",
    "predictions_svm_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO, afficher le score de ce nouveau modèle avec evaluate_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test d'un nouveau modèle : réseau de neurones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Keras a un fonctionnement séquentiel, nous allons déclarer les couches de notre réseau de neurones \n",
    "# qui seront ensuite passées à un constructeur\n",
    "kerasNet1 = Sequential([\n",
    "        Dense(400, batch_input_shape=(None,784), init='uniform'), #None means batch of any size\n",
    "        Activation('tanh'),\n",
    "        Dense(10),\n",
    "        Activation('softmax'),\n",
    "    ])\n",
    "# On déclare également une fonction d'optimisation et ses paramètres (learning rate, initialisation des poids...)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# On fait appel au constructeur qui compile les différents objets créés précédemment\n",
    "kerasNet1.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Afin de pouvoir entrainer notre modèle, nous devons convertir les labels dans un format binaire\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train_b = to_categorical(y_train)\n",
    "y_val_b = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On entraine le modèle\n",
    "x_train  = np.array(x_train)\n",
    "x_val = np.array(x_val)\n",
    "kerasNet1.fit(x_train, y_train_b, nb_epoch=10, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_cnn_1 = kerasNet1.predict(np.array(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Etudions la manière dont notre modèle se généralise, pour cela on va de nouveau entrainer notre modèle\n",
    "# Puis, pour l'occasion j'ai créé des fonctions de callback\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class TrainingHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_losses = [] # init losses list\n",
    "        self.val_losses = [] # init losses list\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}): #we could use on_batch_end\n",
    "        self.train_losses.append(logs.get('loss')) # append losses to the list\n",
    "        self.val_losses.append(logs.get('val_loss')) # append losses to the list\n",
    "            \n",
    "history = TrainingHistory() # instanciate the custom callback object\n",
    "\n",
    "# On entraine une nouvelle fois notre réseau mais cette fois en spécifiant la fonction de callback\n",
    "kerasNet1.fit(x_train, y_train_b, nb_epoch=50, batch_size=100, validation_data=(x_val, y_val_b), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualisons l'erreure commise par notre modèle\n",
    "fig = plt.figure(figsize=(5, 2.5))\n",
    "x = np.linspace(0, len(history.train_losses),len(history.train_losses))\n",
    "plt.plot(x, history.val_losses,  label='val_losses')\n",
    "plt.plot(x, history.train_losses,  label='train_losses')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Etape 8 - Incrémentez ! Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "x_flipped ="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
